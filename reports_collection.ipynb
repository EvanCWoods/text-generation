{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "reports-collection.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMgnqI3oBY4pJkBhfS3EMLj"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMQHGQqef2TQ"
      },
      "source": [
        "# Import Libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPScHUYmfpSz"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_E9Nt-jgBBi"
      },
      "source": [
        "# Get The Data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeKXKx7aDqD6",
        "outputId": "f3bf43f0-7d2f-434e-d2c4-79e48aa3547f"
      },
      "source": [
        "filepath = '/content/data.txt'\n",
        "\n",
        "with open(filepath) as f:\n",
        "  data = f.read()\n",
        "\n",
        "print(data[:1000])"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "In the technological era the ability to work deeply and thoughtfully on a specific issue is becoming increasingly rare. \n",
            "The constant connectivity of individuals is a leading cause of the alarming lack of ability to go deep into a subject and it is becoming more rare each day. \n",
            "This book starts in part one by explaining the reasons for the ability to work deeply being so important, especially in today's age. \n",
            "These are: deep work is rare, valuable and meaningful. \n",
            "The idea is that the ability to think deeply is a commodity rarer than any other and as a result is becoming increasingly valuable. \n",
            "The book then discusses in part two what the leading causes for the mental rut that is keeping people from achieving the ability to think deeply and ways to get out of it.  \n",
            "These are: Practice working deeply,  embrace boredom, quit social media and drain the shallows.\n",
            "\n",
            "Part one of the book sets the concepts behind a better understanding of what deep work is and why it is so important to be able\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nikx7nhNgT46"
      },
      "source": [
        "# Preprocess The Data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpHhhg2bDWtX",
        "outputId": "74eb8ebf-11d0-43ec-beee-49bfe101a5df"
      },
      "source": [
        "corpus = data.split('.')\n",
        "print(corpus[0:3])"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['In the technological era the ability to work deeply and thoughtfully on a specific issue is becoming increasingly rare', ' \\nThe constant connectivity of individuals is a leading cause of the alarming lack of ability to go deep into a subject and it is becoming more rare each day', \" \\nThis book starts in part one by explaining the reasons for the ability to work deeply being so important, especially in today's age\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NK3lhbfnGpEn",
        "outputId": "b4c8f440-fe89-4e88-d75e-a09ad392e65a"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "word_index = tokenizer.word_index\n",
        "total_words = len(word_index) + 1\n",
        "print(total_words)"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "971\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QFOAg_kGfB2",
        "outputId": "455b875c-d9c8-4533-833a-6f76a1cf0fe6"
      },
      "source": [
        "input_sequences = []\n",
        "\n",
        "for line in corpus:\n",
        "  token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "  for i in range(1, len(token_list)):\n",
        "    n_gram_sequences = token_list[:i+1]\n",
        "    input_sequences.append(n_gram_sequences)\n",
        "  \n",
        "max_sequence_length = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(tf.keras.preprocessing.sequence.pad_sequences(input_sequences,\n",
        "                                                                         maxlen=max_sequence_length))\n",
        "\n",
        "print(max_sequence_length)"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "130\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdJvRMTFIZw2"
      },
      "source": [
        "xs = input_sequences[:,:-1]\n",
        "ys = input_sequences[:,-1]\n",
        "labels = tf.keras.utils.to_categorical(ys, num_classes=total_words)"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFJBAiAkDqqB"
      },
      "source": [
        "# Create The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPdmkROWH5I5",
        "outputId": "082ebf07-a28c-4d55-c8b6-7d88cf844f46"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Embedding(total_words, 32, input_length=max_sequence_length),\n",
        "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
        "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
        "  tf.keras.layers.LSTM(64),\n",
        "  tf.keras.layers.Dense(64, activation='relu'),\n",
        "  tf.keras.layers.Dense(485, activation='relu'),\n",
        "  tf.keras.layers.Dense(971, activation='softmax'),\n",
        "])\n",
        "model.summary()"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 130, 32)           31072     \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 130, 128)          49664     \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 130, 128)          98816     \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 64)                49408     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 485)               31525     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 971)               471906    \n",
            "=================================================================\n",
            "Total params: 736,551\n",
            "Trainable params: 736,551\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mPw5eXUIobm",
        "outputId": "692ebf42-31bd-4ed8-d3d0-86f9b79f4dfe"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(xs, labels, epochs=100)"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 130) for input KerasTensor(type_spec=TensorSpec(shape=(None, 130), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None, 129).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 130) for input KerasTensor(type_spec=TensorSpec(shape=(None, 130), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None, 129).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 130) for input KerasTensor(type_spec=TensorSpec(shape=(None, 130), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None, 129).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 130) for input KerasTensor(type_spec=TensorSpec(shape=(None, 130), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None, 129).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "92/92 [==============================] - 32s 258ms/step - loss: 6.3520 - accuracy: 0.0510\n",
            "Epoch 2/100\n",
            "92/92 [==============================] - 24s 258ms/step - loss: 5.9994 - accuracy: 0.0531\n",
            "Epoch 3/100\n",
            "92/92 [==============================] - 24s 259ms/step - loss: 5.8888 - accuracy: 0.0552\n",
            "Epoch 4/100\n",
            "92/92 [==============================] - 24s 259ms/step - loss: 5.7246 - accuracy: 0.0528\n",
            "Epoch 5/100\n",
            "92/92 [==============================] - 24s 258ms/step - loss: 5.5658 - accuracy: 0.0596\n",
            "Epoch 6/100\n",
            "92/92 [==============================] - 24s 258ms/step - loss: 5.4480 - accuracy: 0.0719\n",
            "Epoch 7/100\n",
            "92/92 [==============================] - 24s 260ms/step - loss: 5.3566 - accuracy: 0.0788\n",
            "Epoch 8/100\n",
            "92/92 [==============================] - 24s 259ms/step - loss: 5.2500 - accuracy: 0.0815\n",
            "Epoch 9/100\n",
            "92/92 [==============================] - 24s 259ms/step - loss: 5.1382 - accuracy: 0.0891\n",
            "Epoch 10/100\n",
            "92/92 [==============================] - 24s 258ms/step - loss: 5.0095 - accuracy: 0.0990\n",
            "Epoch 11/100\n",
            "92/92 [==============================] - 24s 260ms/step - loss: 4.8939 - accuracy: 0.0956\n",
            "Epoch 12/100\n",
            "92/92 [==============================] - 24s 259ms/step - loss: 4.7994 - accuracy: 0.1062\n",
            "Epoch 13/100\n",
            "92/92 [==============================] - 24s 259ms/step - loss: 4.7000 - accuracy: 0.1083\n",
            "Epoch 14/100\n",
            "92/92 [==============================] - 24s 258ms/step - loss: 4.5964 - accuracy: 0.1120\n",
            "Epoch 15/100\n",
            "92/92 [==============================] - 24s 258ms/step - loss: 4.5141 - accuracy: 0.1185\n",
            "Epoch 16/100\n",
            "92/92 [==============================] - 24s 259ms/step - loss: 4.4336 - accuracy: 0.1216\n",
            "Epoch 17/100\n",
            "92/92 [==============================] - 24s 258ms/step - loss: 4.3465 - accuracy: 0.1261\n",
            "Epoch 18/100\n",
            "92/92 [==============================] - 24s 260ms/step - loss: 4.2777 - accuracy: 0.1268\n",
            "Epoch 19/100\n",
            "92/92 [==============================] - 24s 259ms/step - loss: 4.2061 - accuracy: 0.1367\n",
            "Epoch 20/100\n",
            "92/92 [==============================] - 24s 258ms/step - loss: 4.1156 - accuracy: 0.1401\n",
            "Epoch 21/100\n",
            "92/92 [==============================] - 24s 259ms/step - loss: 4.0392 - accuracy: 0.1459\n",
            "Epoch 22/100\n",
            "92/92 [==============================] - 24s 259ms/step - loss: 3.9797 - accuracy: 0.1501\n",
            "Epoch 23/100\n",
            "92/92 [==============================] - 24s 259ms/step - loss: 3.9123 - accuracy: 0.1559\n",
            "Epoch 24/100\n",
            "92/92 [==============================] - 24s 260ms/step - loss: 3.8419 - accuracy: 0.1634\n",
            "Epoch 25/100\n",
            "92/92 [==============================] - 24s 259ms/step - loss: 3.7815 - accuracy: 0.1682\n",
            "Epoch 26/100\n",
            "92/92 [==============================] - 24s 261ms/step - loss: 3.7084 - accuracy: 0.1668\n",
            "Epoch 27/100\n",
            "92/92 [==============================] - 24s 259ms/step - loss: 3.6820 - accuracy: 0.1781\n",
            "Epoch 28/100\n",
            "92/92 [==============================] - 24s 259ms/step - loss: 3.6108 - accuracy: 0.1733\n",
            "Epoch 29/100\n",
            "92/92 [==============================] - 24s 259ms/step - loss: 3.5429 - accuracy: 0.1840\n",
            "Epoch 30/100\n",
            "92/92 [==============================] - 24s 259ms/step - loss: 3.4947 - accuracy: 0.1802\n",
            "Epoch 31/100\n",
            "92/92 [==============================] - 24s 259ms/step - loss: 3.4480 - accuracy: 0.1953\n",
            "Epoch 32/100\n",
            "92/92 [==============================] - 24s 259ms/step - loss: 3.3958 - accuracy: 0.1939\n",
            "Epoch 33/100\n",
            "92/92 [==============================] - 24s 259ms/step - loss: 3.3386 - accuracy: 0.1980\n",
            "Epoch 34/100\n",
            "92/92 [==============================] - 24s 259ms/step - loss: 3.3054 - accuracy: 0.2001\n",
            "Epoch 35/100\n",
            "92/92 [==============================] - 24s 259ms/step - loss: 3.2423 - accuracy: 0.2114\n",
            "Epoch 36/100\n",
            "92/92 [==============================] - 24s 259ms/step - loss: 3.2046 - accuracy: 0.2086\n",
            "Epoch 37/100\n",
            "92/92 [==============================] - 24s 259ms/step - loss: 3.1406 - accuracy: 0.2158\n",
            "Epoch 38/100\n",
            "92/92 [==============================] - 24s 259ms/step - loss: 3.0982 - accuracy: 0.2217\n",
            "Epoch 39/100\n",
            "92/92 [==============================] - 24s 259ms/step - loss: 3.0434 - accuracy: 0.2155\n",
            "Epoch 40/100\n",
            "92/92 [==============================] - 24s 259ms/step - loss: 3.0209 - accuracy: 0.2234\n",
            "Epoch 41/100\n",
            "92/92 [==============================] - 24s 260ms/step - loss: 2.9697 - accuracy: 0.2425\n",
            "Epoch 42/100\n",
            "92/92 [==============================] - 24s 258ms/step - loss: 2.9150 - accuracy: 0.2398\n",
            "Epoch 43/100\n",
            "92/92 [==============================] - 24s 259ms/step - loss: 2.8757 - accuracy: 0.2631\n",
            "Epoch 44/100\n",
            "92/92 [==============================] - 24s 260ms/step - loss: 2.8174 - accuracy: 0.2439\n",
            "Epoch 45/100\n",
            "92/92 [==============================] - 24s 258ms/step - loss: 2.7648 - accuracy: 0.2703\n",
            "Epoch 46/100\n",
            "92/92 [==============================] - 24s 258ms/step - loss: 2.7353 - accuracy: 0.2645\n",
            "Epoch 47/100\n",
            "92/92 [==============================] - 24s 259ms/step - loss: 2.6717 - accuracy: 0.2730\n",
            "Epoch 48/100\n",
            "92/92 [==============================] - 24s 260ms/step - loss: 2.6482 - accuracy: 0.2861\n",
            "Epoch 49/100\n",
            "92/92 [==============================] - 24s 260ms/step - loss: 2.6466 - accuracy: 0.2864\n",
            "Epoch 50/100\n",
            "92/92 [==============================] - 24s 261ms/step - loss: 2.5891 - accuracy: 0.2919\n",
            "Epoch 51/100\n",
            "92/92 [==============================] - 24s 261ms/step - loss: 2.5447 - accuracy: 0.3042\n",
            "Epoch 52/100\n",
            "92/92 [==============================] - 24s 259ms/step - loss: 2.4962 - accuracy: 0.3070\n",
            "Epoch 53/100\n",
            "92/92 [==============================] - 24s 259ms/step - loss: 2.4603 - accuracy: 0.3200\n",
            "Epoch 54/100\n",
            "92/92 [==============================] - 24s 259ms/step - loss: 2.4094 - accuracy: 0.3261\n",
            "Epoch 55/100\n",
            "92/92 [==============================] - 24s 258ms/step - loss: 2.4064 - accuracy: 0.3165\n",
            "Epoch 56/100\n",
            "92/92 [==============================] - 24s 259ms/step - loss: 2.3530 - accuracy: 0.3333\n",
            "Epoch 57/100\n",
            "92/92 [==============================] - 24s 260ms/step - loss: 2.2951 - accuracy: 0.3436\n",
            "Epoch 58/100\n",
            "92/92 [==============================] - 24s 259ms/step - loss: 2.2565 - accuracy: 0.3481\n",
            "Epoch 59/100\n",
            "92/92 [==============================] - 24s 259ms/step - loss: 2.2700 - accuracy: 0.3556\n",
            "Epoch 60/100\n",
            "92/92 [==============================] - 24s 258ms/step - loss: 2.2062 - accuracy: 0.3553\n",
            "Epoch 61/100\n",
            "92/92 [==============================] - 24s 259ms/step - loss: 2.1690 - accuracy: 0.3734\n",
            "Epoch 62/100\n",
            "92/92 [==============================] - 24s 260ms/step - loss: 2.1671 - accuracy: 0.3672\n",
            "Epoch 63/100\n",
            "92/92 [==============================] - 24s 260ms/step - loss: 2.1175 - accuracy: 0.3786\n",
            "Epoch 64/100\n",
            "92/92 [==============================] - 24s 261ms/step - loss: 2.0615 - accuracy: 0.3964\n",
            "Epoch 65/100\n",
            "92/92 [==============================] - 24s 262ms/step - loss: 2.0084 - accuracy: 0.4012\n",
            "Epoch 66/100\n",
            "92/92 [==============================] - 24s 260ms/step - loss: 1.9367 - accuracy: 0.4224\n",
            "Epoch 67/100\n",
            "92/92 [==============================] - 24s 260ms/step - loss: 1.9342 - accuracy: 0.4310\n",
            "Epoch 68/100\n",
            "92/92 [==============================] - 24s 260ms/step - loss: 1.9405 - accuracy: 0.4169\n",
            "Epoch 69/100\n",
            "92/92 [==============================] - 24s 258ms/step - loss: 1.9310 - accuracy: 0.4176\n",
            "Epoch 70/100\n",
            "92/92 [==============================] - 24s 259ms/step - loss: 1.8801 - accuracy: 0.4354\n",
            "Epoch 71/100\n",
            "92/92 [==============================] - 24s 262ms/step - loss: 1.8775 - accuracy: 0.4286\n",
            "Epoch 72/100\n",
            "92/92 [==============================] - 24s 263ms/step - loss: 1.8673 - accuracy: 0.4481\n",
            "Epoch 73/100\n",
            "92/92 [==============================] - 24s 261ms/step - loss: 1.7901 - accuracy: 0.4645\n",
            "Epoch 74/100\n",
            "92/92 [==============================] - 24s 259ms/step - loss: 1.7041 - accuracy: 0.4861\n",
            "Epoch 75/100\n",
            "92/92 [==============================] - 24s 259ms/step - loss: 1.6588 - accuracy: 0.4896\n",
            "Epoch 76/100\n",
            "92/92 [==============================] - 24s 260ms/step - loss: 1.6283 - accuracy: 0.5074\n",
            "Epoch 77/100\n",
            "92/92 [==============================] - 24s 260ms/step - loss: 1.5963 - accuracy: 0.5170\n",
            "Epoch 78/100\n",
            "92/92 [==============================] - 24s 260ms/step - loss: 1.6162 - accuracy: 0.5108\n",
            "Epoch 79/100\n",
            "92/92 [==============================] - 24s 259ms/step - loss: 1.5672 - accuracy: 0.5173\n",
            "Epoch 80/100\n",
            "92/92 [==============================] - 24s 261ms/step - loss: 1.5256 - accuracy: 0.5334\n",
            "Epoch 81/100\n",
            "92/92 [==============================] - 24s 262ms/step - loss: 1.5030 - accuracy: 0.5331\n",
            "Epoch 82/100\n",
            "92/92 [==============================] - 24s 263ms/step - loss: 1.4810 - accuracy: 0.5324\n",
            "Epoch 83/100\n",
            "92/92 [==============================] - 24s 264ms/step - loss: 1.4874 - accuracy: 0.5375\n",
            "Epoch 84/100\n",
            "92/92 [==============================] - 24s 262ms/step - loss: 1.4442 - accuracy: 0.5557\n",
            "Epoch 85/100\n",
            "92/92 [==============================] - 24s 261ms/step - loss: 1.4505 - accuracy: 0.5423\n",
            "Epoch 86/100\n",
            "92/92 [==============================] - 24s 264ms/step - loss: 1.3553 - accuracy: 0.5745\n",
            "Epoch 87/100\n",
            "92/92 [==============================] - 24s 262ms/step - loss: 1.3387 - accuracy: 0.5868\n",
            "Epoch 88/100\n",
            "92/92 [==============================] - 24s 261ms/step - loss: 1.3001 - accuracy: 0.5961\n",
            "Epoch 89/100\n",
            "92/92 [==============================] - 24s 260ms/step - loss: 1.2963 - accuracy: 0.5978\n",
            "Epoch 90/100\n",
            "92/92 [==============================] - 24s 260ms/step - loss: 1.2382 - accuracy: 0.6149\n",
            "Epoch 91/100\n",
            "92/92 [==============================] - 24s 260ms/step - loss: 1.1872 - accuracy: 0.6331\n",
            "Epoch 92/100\n",
            "92/92 [==============================] - 24s 260ms/step - loss: 1.2250 - accuracy: 0.6190\n",
            "Epoch 93/100\n",
            "92/92 [==============================] - 24s 262ms/step - loss: 1.2412 - accuracy: 0.6108\n",
            "Epoch 94/100\n",
            "92/92 [==============================] - 24s 260ms/step - loss: 1.2216 - accuracy: 0.6194\n",
            "Epoch 95/100\n",
            "92/92 [==============================] - 24s 259ms/step - loss: 1.1209 - accuracy: 0.6454\n",
            "Epoch 96/100\n",
            "92/92 [==============================] - 24s 260ms/step - loss: 1.0882 - accuracy: 0.6571\n",
            "Epoch 97/100\n",
            "92/92 [==============================] - 24s 259ms/step - loss: 1.0843 - accuracy: 0.6557\n",
            "Epoch 98/100\n",
            "92/92 [==============================] - 24s 260ms/step - loss: 1.0647 - accuracy: 0.6715\n",
            "Epoch 99/100\n",
            "92/92 [==============================] - 24s 261ms/step - loss: 1.0455 - accuracy: 0.6697\n",
            "Epoch 100/100\n",
            "92/92 [==============================] - 24s 259ms/step - loss: 1.0479 - accuracy: 0.6663\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bKHMy7fIzxF"
      },
      "source": [
        "def plot(history, metric):\n",
        "  plt.plot(history.history[metric], label=metric)\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel(metric)\n",
        "  plt.legend()"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "hFvhIMKoJQ6U",
        "outputId": "e2a8703e-0384-4593-ee5a-7ee78b135733"
      },
      "source": [
        "acc_plot = plot(history=history, metric='accuracy')\n",
        "loss_plot = plot(history=history, metric='loss')\n",
        "\n",
        "acc_plot\n",
        "loss_plot"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S02MjSrWSKYN",
        "outputId": "0f238c1c-221f-4164-d9cc-a5e9542a22c7"
      },
      "source": [
        "seed_text = 'the first time'\n",
        "next_words = 25\n",
        "\n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_length-1, padding='pre')\n",
        "\tpredicted = model.predict_classes(token_list, verbose=0)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print()\n",
        "print()\n",
        "print(seed_text)"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "the first time can maximize 12 leaving to solve yourself good what you criticize he helped the broader 7 â€œpursue what is meaningful not only was almost impossible\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37iSfjw0TQeG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}